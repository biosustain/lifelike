{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create BioCyc GDS databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "github project:  kg-prototypes  \n",
    "branch: graphdb_load\n",
    "\n",
    "#### Steps\n",
    "1. Download individual organism data files.  \n",
    "http://bioinformatics.ai.sri.com/ecocyc/dist/flatfiles-52983746/\n",
    "\n",
    "Curently downloaded files are listed in src/config/config.yml file\n",
    "  - EcoCyc: ecoli_25.5.tar.gz\n",
    "  - HumanCyc: human.tar_25.5.gz\n",
    "  - YeastCyc: yeastcyc_25.5.tar.gz\n",
    "  - PseudomonasCyc: pput160488cyc_25.5.tar.gz\n",
    "  - BsubCyc: bsub_47.tar.gz  \n",
    "  \n",
    "\n",
    "2. Parse the .dat files and process and write formatted data into .tsv files and put into one zip file for liquibase to load into Neo4j graph database  \n",
    "\n",
    "3. Put all post-load scripps into src/config/cypher/biocyc-cypher.yml file, except organism specific cypher queries\n",
    "4. Generate liquibase changelog files\n",
    "5. Move changelog files to migration/liquibase/{dbname}/changelogs folder, and rename.\n",
    "5. Run liquibase update\n",
    "\n",
    "#### Pre-requisition:\n",
    "Since GDS need enzyme name information.  Enzyme database will be loaded into neo4j before loading biocyc data.  The enzyme data will be removed one the enzyme name information is copied to reaction property (displayName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "***ARANGO_USERNAME*** = os.getcwd().split('notebook')[0]\n",
    "sys.path.append(os.path.join(***ARANGO_USERNAME***, 'src'))\n",
    "\n",
    "from biocyc.biocyc_parser import *\n",
    "from biocyc import biocyc_liquibase\n",
    "from biocyc import bsubcyc_liquibase \n",
    "from common.constants import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse biocyc data files and generated processed tsv files\n",
    "#### data source\n",
    "Download the data file from biocyc or https://portal.azure.com/#view/Microsoft_Azure_FileStorage/FileShareMenuBlade/~/overview/storageAccountId/%2Fsubscriptions%2F747d6a13-5882-4572-8560-af80d7df69b5%2FresourceGroups%2F***ARANGO_DB_NAME***-ecosystem%2Fproviders%2FMicrosoft.Storage%2FstorageAccounts%2F***ARANGO_DB_NAME***/path/knowledge-graph/protocol/SMB\n",
    "\n",
    "data files need to put into the input dir: kg-prototypes/graph-db/extraction/data/download/biocyc   \n",
    "\n",
    "#### output dir\n",
    "Parser outputs are written in {kg-prototypes}/graph-db/extraction/data/processed/biocyc.     \n",
    "A zip file be generated in the format {biocyc_dbname}-data-{version}.zip under {output dir}/{biocyc_dbname}, where biocyc_dbname is EcoCyc, HumanCyc etc.\n",
    "\n",
    "The biocyc_dbname/data-source-file mapping is in __kg-prototypes/graph-db/extraction/src/config/config.yml__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-29 16:34:56,948 Load BsubCyc: Species\n",
      "2022-07-29 16:34:57,965 Database file version: \"47\"\n",
      "2022-07-29 16:34:57,966 Parse 47/data/species.dat\n",
      "2022-07-29 16:34:58,571 Parse BsubCyc Species: 1\n",
      "2022-07-29 16:34:58,647 writing Species.tsv\n",
      "2022-07-29 16:34:58,688 writing Species-synonyms.tsv\n",
      "2022-07-29 16:34:58,692 Load BsubCyc: BioCycClass\n",
      "2022-07-29 16:34:58,968 Parse 47/data/classes.dat\n",
      "2022-07-29 16:35:01,687 Parse BsubCyc BioCycClass: 7565\n",
      "2022-07-29 16:35:01,713 writing BioCycClass.tsv\n",
      "2022-07-29 16:35:01,830 writing BioCycClass-synonyms.tsv\n",
      "2022-07-29 16:35:01,907 writing BioCycClass-rels.tsv\n",
      "2022-07-29 16:35:01,942 Load BsubCyc: Compound\n",
      "2022-07-29 16:35:02,084 Parse 47/data/compounds.dat\n",
      "2022-07-29 16:35:05,238 Parse BsubCyc Compound: 5242\n",
      "2022-07-29 16:35:05,305 writing Compound.tsv\n",
      "2022-07-29 16:35:05,564 writing Compound-synonyms.tsv\n",
      "2022-07-29 16:35:05,707 writing Compound-dblinks.tsv\n",
      "2022-07-29 16:35:05,725 writing Compound-rels.tsv\n",
      "2022-07-29 16:35:05,760 Load BsubCyc: DNABindingSite\n",
      "2022-07-29 16:35:06,564 Parse 47/data/dnabindsites.dat\n",
      "2022-07-29 16:35:07,779 Parse BsubCyc DNABindingSite: 831\n",
      "2022-07-29 16:35:07,784 writing DNABindingSite.tsv\n",
      "2022-07-29 16:35:07,794 Load BsubCyc: Gene\n",
      "2022-07-29 16:35:08,099 Parse 47/data/genes.dat\n",
      "2022-07-29 16:35:10,122 Parse BsubCyc Gene: 4536\n",
      "2022-07-29 16:35:10,146 writing Gene.tsv\n",
      "2022-07-29 16:35:10,223 writing Gene-synonyms.tsv\n",
      "2022-07-29 16:35:10,254 Load BsubCyc: Terminator\n",
      "2022-07-29 16:35:10,483 Parse 47/data/terminators.dat\n",
      "2022-07-29 16:35:11,905 Parse BsubCyc Terminator: 1147\n",
      "2022-07-29 16:35:11,913 writing Terminator.tsv\n",
      "2022-07-29 16:35:11,922 Load BsubCyc: Promoter\n",
      "2022-07-29 16:35:12,251 Parse 47/data/promoters.dat\n",
      "2022-07-29 16:35:13,863 Parse BsubCyc Promoter: 1235\n",
      "2022-07-29 16:35:13,884 writing Promoter.tsv\n",
      "2022-07-29 16:35:13,967 writing Promoter-synonyms.tsv\n",
      "2022-07-29 16:35:13,978 Load BsubCyc: TranscriptionUnit\n",
      "2022-07-29 16:35:14,897 Parse 47/data/transunits.dat\n",
      "2022-07-29 16:35:17,033 Parse BsubCyc TranscriptionUnit: 1647\n",
      "2022-07-29 16:35:17,044 writing TranscriptionUnit.tsv\n",
      "2022-07-29 16:35:17,087 writing TranscriptionUnit-rels.tsv\n",
      "2022-07-29 16:35:17,112 Load BsubCyc: RNA\n",
      "2022-07-29 16:35:17,119 Parse 47/data/rnas.dat\n",
      "2022-07-29 16:35:18,402 Parse BsubCyc RNA: 295\n",
      "2022-07-29 16:35:18,408 writing RNA.tsv\n",
      "2022-07-29 16:35:18,422 writing RNA-rels.tsv\n",
      "2022-07-29 16:35:18,428 Load BsubCyc: Protein\n",
      "2022-07-29 16:35:18,913 Parse 47/data/proteins.dat\n",
      "2022-07-29 16:35:24,423 Parse 47/data/protligandcplxes.dat\n",
      "2022-07-29 16:35:26,277 Parse BsubCyc Protein: 4569\n",
      "2022-07-29 16:35:26,310 writing Protein.tsv\n",
      "2022-07-29 16:35:26,465 writing Protein-synonyms.tsv\n",
      "2022-07-29 16:35:26,602 writing Protein-dblinks.tsv\n",
      "2022-07-29 16:35:26,670 writing Protein-rels.tsv\n",
      "2022-07-29 16:35:26,687 Load BsubCyc: Reaction\n",
      "2022-07-29 16:35:27,144 Parse 47/data/reactions.dat\n",
      "2022-07-29 16:35:28,551 Parse BsubCyc Reaction: 1727\n",
      "2022-07-29 16:35:28,561 writing Reaction.tsv\n",
      "2022-07-29 16:35:28,599 writing Reaction-synonyms.tsv\n",
      "2022-07-29 16:35:28,644 writing Reaction-dblinks.tsv\n",
      "2022-07-29 16:35:28,658 writing Reaction-rels.tsv\n",
      "2022-07-29 16:35:28,693 Load BsubCyc: Pathway\n",
      "2022-07-29 16:35:28,818 Parse 47/data/pathways.dat\n",
      "2022-07-29 16:35:30,077 Parse BsubCyc Pathway: 327\n",
      "2022-07-29 16:35:30,081 writing Pathway.tsv\n",
      "2022-07-29 16:35:30,104 writing Pathway-synonyms.tsv\n",
      "2022-07-29 16:35:30,118 writing Pathway-rels.tsv\n",
      "2022-07-29 16:35:30,127 Load BsubCyc: EnzReaction\n",
      "2022-07-29 16:35:30,592 Parse 47/data/enzrxns.dat\n",
      "2022-07-29 16:35:31,937 Parse BsubCyc EnzReaction: 1356\n",
      "2022-07-29 16:35:31,945 writing EnzReaction.tsv\n",
      "2022-07-29 16:35:31,966 writing EnzReaction-rels.tsv\n",
      "2022-07-29 16:35:31,976 Load BsubCyc: Regulation\n",
      "2022-07-29 16:35:32,133 Parse 47/data/regulation.dat\n",
      "2022-07-29 16:35:33,174 Parse BsubCyc Regulation: 917\n",
      "2022-07-29 16:35:33,180 writing Regulation.tsv\n",
      "2022-07-29 16:35:33,199 writing Regulation-rels.tsv\n",
      "2022-07-29 16:35:33,214 create zip file: BsubCyc-data-47.zip\n"
     ]
    }
   ],
   "source": [
    "# set the biocyc_db to process\n",
    "biocyc_db = DB_BSUBCYC\n",
    "\n",
    "parser = BiocycParser(biocyc_db)\n",
    "parser.parse_and_write_data_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Liquibase changelogs file\n",
    "\n",
    "Liquibase changelog generator expects the input file to be the output zip file from previous step. \n",
    "5 changelog files will be generated.  \n",
    "\n",
    "1. init-changelog:  the scripts will read the parser output zip file, and load data into neo4j database  \n",
    "        \n",
    "2. post load changelogs: this is part of Lifelike biocyc database updates\n",
    "    - link genes to NCBI gene\n",
    "    - set node display name\n",
    "    - set node description, including reaction description as an equation without stoichiometry\n",
    "    - set reaction enzyme_name \n",
    "    - set pathways for gene (for annotation)\n",
    "    - set node property entityType   \n",
    "       \n",
    "3. gds no-collapse changelogs: This is used to generate non-collapse gds database\n",
    "    - all changes listed in #2\n",
    "    - correction reaction input and output directions\n",
    "    - create reversed reactions for reversible reactions if input and output are not the same. Put postfix '_r' in the reversed reaction eid and displayName\n",
    "    - reverse gene to TranscriptionUnit relationship as (TranscriptionUnit)-[:HAS_GENE]->(Gene)\n",
    "    - delete DNA binding site nodes\n",
    "    - delete TYPE_OF relationships\n",
    "    - remove orphan BioCycClass nodes\n",
    "    - remove Enzyme nodes (from Enzyme database)\n",
    "    - set node synonyms property and remove Synonym nodes\n",
    "    - label some compounds as CurrencyMetabolite\n",
    "    - change description property to detail since description is used by sankey for other purpose   \n",
    "    \n",
    "4. gds reg-collapse chanagelogs: This is used to generate reg-collapse gds database.  The database will have parallel edges, therefore need to use multi-graph to run the analysis and traces\n",
    "    - all changes listed in #3\n",
    "    - Collapse reglations\n",
    "        - for reglation with mode '+', change the relationship to 'ACTIVATES' then remove regulation node\n",
    "        - for reglation with mode '-', change the relationship to 'INHIBITS' then remove regulation node\n",
    "        for reglation with mode '', change the relationship to 'REGULATES' then remove regulation node\n",
    "        \n",
    "5. gds changelogs:  This is used to create the general gds database. It has Regulation and EnzReaction nodes collapsed and removed. Multi-graph is needed to run the analysis and traces.\n",
    "    - all changes listed in #4\n",
    "    - collapse EnzReaction\n",
    "        - for EnzReaction regulations, move the regulator to regulate the reactions directly\n",
    "        - for EnzReaction catalyzes, move the protein to catalyze reactions directly\n",
    "        - delete all EnzReaction nodes\n",
    "\n",
    "### Note:\n",
    "The following scripts will generate the general changelogs for different gds databases and ***ARANGO_DB_NAME*** update changelogs.  The ***ARANGO_DB_NAME*** update will need the changelog-xxx-init-xxx.xml and changelog-xxx-post-load-xxx.xml files.  However, since different organism gene naming(accessions) could be different, and they are not always matched with NCBI gene locus tags, you may need different cypher queries to do the gene-gene mapping.  The bsubcyc_liquibase.py is an example about how to override the general cypher queries for the gene mapping.  You could also just manually run the cypher queries after loading biocyc data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/dommas/Projects/kg-prototypes/graph-db/extraction/data/processed/biocyc/ecocyc/EcoCyc-data-25.5.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m biocyc_dbname \u001b[38;5;241m=\u001b[39m DB_ECOCYC\n\u001b[1;32m      4\u001b[0m author \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrcai\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# change to your name\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mbiocyc_liquibase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_changelog_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzip_datafile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbiocyc_dbname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthor\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/kg-prototypes/graph-db/extraction/src/biocyc/biocyc_liquibase.py:189\u001b[0m, in \u001b[0;36mgenerate_changelog_files\u001b[0;34m(zip_datafile, biocyc_dbname, author)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03mThe code will generate three changelog files: init_changelog, post_load_changelog and gds_changelog.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03minit_changelog loads all the parser output data into neo4j;\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m \n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    188\u001b[0m proc \u001b[38;5;241m=\u001b[39m BioCycChangeLogsGenerator(author, biocyc_dbname, zip_datafile, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 189\u001b[0m \u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_init_changelog_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m proc \u001b[38;5;241m=\u001b[39m BioCycCypherChangeLogsGenerator(author, biocyc_dbname)\n\u001b[1;32m    192\u001b[0m proc\u001b[38;5;241m.\u001b[39mgenerate_post_load_changlog_file()\n",
      "File \u001b[0;32m~/Projects/kg-prototypes/graph-db/extraction/src/biocyc/biocyc_liquibase.py:105\u001b[0m, in \u001b[0;36mBioCycChangeLogsGenerator.generate_init_changelog_file\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_init_changelog_file\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_all_change_sets\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     changelog_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchangelog-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbiocyc_dbname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-init-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdate_tag\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.xml\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_changelog_file(changelog_file)\n",
      "File \u001b[0;32m~/Projects/kg-prototypes/graph-db/extraction/src/common/liquibase_changelog_generator.py:62\u001b[0m, in \u001b[0;36mChangeLogFileGenerator.add_all_change_sets\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_all_change_sets\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_load:\n\u001b[0;32m---> 62\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_index_changesets\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_node_changesets()\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_synonym_changesets()\n",
      "File \u001b[0;32m~/Projects/kg-prototypes/graph-db/extraction/src/common/liquibase_changelog_generator.py:89\u001b[0m, in \u001b[0;36mChangeLogFileGenerator.add_index_changesets\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCreate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdb_source\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m constraints and indexes\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     88\u001b[0m comment \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreate constraints and indexes for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdb_source\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m nodes, created on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdate_tag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 89\u001b[0m queries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_create_index_queries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m query_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(queries)\n\u001b[1;32m     91\u001b[0m changeset \u001b[38;5;241m=\u001b[39m ChangeSet(\u001b[38;5;28mid\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauthor, comment, query_str)\n",
      "File \u001b[0;32m~/Projects/kg-prototypes/graph-db/extraction/src/biocyc/biocyc_liquibase.py:23\u001b[0m, in \u001b[0;36mBioCycChangeLogsGenerator.get_create_index_queries\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_create_index_queries\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_common_index_queries()\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_entity_index_queries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_quieries\n",
      "File \u001b[0;32m~/Projects/kg-prototypes/graph-db/extraction/src/biocyc/biocyc_liquibase.py:37\u001b[0m, in \u001b[0;36mBioCycChangeLogsGenerator.add_entity_index_queries\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_entity_index_queries\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocessed_data_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzipfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;28mzip\u001b[39m:\n\u001b[1;32m     38\u001b[0m         filenames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m\u001b[38;5;241m.\u001b[39mnamelist()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m entity \u001b[38;5;129;01min\u001b[39;00m ENTITIES:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/zipfile.py:1251\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1251\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   1253\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/dommas/Projects/kg-prototypes/graph-db/extraction/data/processed/biocyc/ecocyc/EcoCyc-data-25.5.zip'"
     ]
    }
   ],
   "source": [
    "# get the zip file name from previous step output message\n",
    "zip_datafile = 'EcoCyc-data-25.5.zip'\n",
    "biocyc_dbname = DB_ECOCYC\n",
    "author = 'rcai'  # change to your name\n",
    "biocyc_liquibase.generate_changelog_files(zip_datafile, biocyc_dbname, author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run liquibase update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Install liquibase\n",
    "Follow steps in __kg-prototypes/graph-db/migration/liquibase-src/README.md__ to install liquibase, jar files, including the custom java classes.\n",
    "\n",
    "#### 2. Set up database folder for changelogs\n",
    "- copy changelog-mater.xml\n",
    "- copy liquibase.properties, and change the database settings (url, password)\n",
    "- add changelog files into the folder changelogs, and order the changelog files as changelog-xxxx. Liquibase updates will be based on the changelog file name sequence\n",
    "- copy the processed zip file (e.g. PsyringaeCyc-data-24.0.zip) from processed biocyc folder into the folder \"parameter.localSaveFileDir\"\n",
    "\n",
    "### 3. Run liquibase update\n",
    "- create an database in neo4j with name matching the liquibase.properties\n",
    "- run command: \n",
    "```\n",
    "liquibase --log-level=info update\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add new Biocyc GDS databases (different organism)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download the data file from biocyc, and put into {data_dir}/download/biocyc folder\n",
    "2. Add a new db variable in common/constants.py\n",
    "3. In config/congig.yml file, add the dbname-filename mapping \n",
    "4. Run BiocycParser.parse_and_write_data_files\n",
    "5. Run biocyc_liquibase.generate_changelog_files\n",
    "6. create database in neo4j, and run liquibase update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
