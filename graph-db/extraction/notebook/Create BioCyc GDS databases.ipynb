{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create BioCyc GDS databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "github project:  kg-prototypes  \n",
    "branch: graphdb_load\n",
    "\n",
    "#### Steps\n",
    "1. Download individual organism data files.  \n",
    "http://bioinformatics.ai.sri.com/ecocyc/dist/flatfiles-52983746/\n",
    "\n",
    "Curently downloaded files are listed in src/config/config.yml file\n",
    "  - EcoCyc: ecoli_25.5.tar.gz\n",
    "  - HumanCyc: human.tar_25.5.gz\n",
    "  - YeastCyc: yeastcyc_25.5.tar.gz\n",
    "  - PseudomonasCyc: pput160488cyc_25.5.tar.gz\n",
    "  - BsubCyc: bsub_47.tar.gz  \n",
    "  \n",
    "\n",
    "2. Parse the .dat files and process and write formatted data into .tsv files and put into one zip file for liquibase to load into Neo4j graph database  \n",
    "\n",
    "3. Put all post-load scripps into src/config/cypher/biocyc-cypher.yml file, except organism specific cypher queries\n",
    "4. Generate liquibase changelog files\n",
    "5. Move changelog files to migration/liquibase/{dbname}/changelogs folder, and rename.\n",
    "5. Run liquibase update\n",
    "\n",
    "#### Pre-requisition:\n",
    "Since GDS need enzyme name information.  Enzyme database will be loaded into neo4j before loading biocyc data.  The enzyme data will be removed one the enzyme name information is copied to reaction property (displayName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "root = os.getcwd().split('notebook')[0]\n",
    "sys.path.append(os.path.join(root, 'src'))\n",
    "\n",
    "from biocyc.biocyc_parser import *\n",
    "from biocyc import biocyc_liquibase\n",
    "from biocyc import bsubcyc_liquibase \n",
    "from common.constants import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse biocyc data files and generated processed tsv files\n",
    "#### data source\n",
    "Download the data file from biocyc or https://portal.azure.com/#view/Microsoft_Azure_FileStorage/FileShareMenuBlade/~/overview/storageAccountId/%2Fsubscriptions%2F747d6a13-5882-4572-8560-af80d7df69b5%2FresourceGroups%2Flifelike-ecosystem%2Fproviders%2FMicrosoft.Storage%2FstorageAccounts%2Flifelike/path/knowledge-graph/protocol/SMB\n",
    "\n",
    "data files need to put into the input dir: kg-prototypes/graph-db/extraction/data/download/biocyc   \n",
    "\n",
    "#### output dir\n",
    "Parser outputs are written in {kg-prototypes}/graph-db/extraction/data/processed/biocyc.     \n",
    "A zip file be generated in the format {biocyc_dbname}-data-{version}.zip under {output dir}/{biocyc_dbname}, where biocyc_dbname is EcoCyc, HumanCyc etc.\n",
    "\n",
    "The biocyc_dbname/data-source-file mapping is in __kg-prototypes/graph-db/extraction/src/config/config.yml__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 09:55:16,927 Load BsubCyc: Species\n",
      "2022-07-07 09:55:17,632 Database file version: \"47\"\n",
      "2022-07-07 09:55:17,633 Parse 47/data/species.dat\n",
      "2022-07-07 09:55:18,109 Parse BsubCyc Species: 1\n",
      "2022-07-07 09:55:18,112 writing Species.tsv\n",
      "2022-07-07 09:55:18,124 writing Species-synonyms.tsv\n",
      "2022-07-07 09:55:18,126 Load BsubCyc: BioCycClass\n",
      "2022-07-07 09:55:18,324 Parse 47/data/classes.dat\n",
      "2022-07-07 09:55:19,779 Parse BsubCyc BioCycClass: 7565\n",
      "2022-07-07 09:55:19,789 writing BioCycClass.tsv\n",
      "2022-07-07 09:55:19,857 writing BioCycClass-synonyms.tsv\n",
      "2022-07-07 09:55:19,973 writing BioCycClass-rels.tsv\n",
      "2022-07-07 09:55:19,998 Load BsubCyc: Compound\n",
      "2022-07-07 09:55:20,117 Parse 47/data/compounds.dat\n",
      "2022-07-07 09:55:21,502 Parse BsubCyc Compound: 5242\n",
      "2022-07-07 09:55:21,514 writing Compound.tsv\n",
      "2022-07-07 09:55:21,594 writing Compound-synonyms.tsv\n",
      "2022-07-07 09:55:21,656 writing Compound-dblinks.tsv\n",
      "2022-07-07 09:55:21,663 writing Compound-rels.tsv\n",
      "2022-07-07 09:55:21,677 Load BsubCyc: DNABindingSite\n",
      "2022-07-07 09:55:22,052 Parse 47/data/dnabindsites.dat\n",
      "2022-07-07 09:55:22,827 Parse BsubCyc DNABindingSite: 831\n",
      "2022-07-07 09:55:22,831 writing DNABindingSite.tsv\n",
      "2022-07-07 09:55:22,837 Load BsubCyc: Gene\n",
      "2022-07-07 09:55:23,059 Parse 47/data/genes.dat\n",
      "2022-07-07 09:55:24,235 Parse BsubCyc Gene: 4536\n",
      "2022-07-07 09:55:24,245 writing Gene.tsv\n",
      "2022-07-07 09:55:24,295 writing Gene-synonyms.tsv\n",
      "2022-07-07 09:55:24,311 Load BsubCyc: Terminator\n",
      "2022-07-07 09:55:24,475 Parse 47/data/terminators.dat\n",
      "2022-07-07 09:55:25,343 Parse BsubCyc Terminator: 1147\n",
      "2022-07-07 09:55:25,346 writing Terminator.tsv\n",
      "2022-07-07 09:55:25,352 Load BsubCyc: Promoter\n",
      "2022-07-07 09:55:25,518 Parse 47/data/promoters.dat\n",
      "2022-07-07 09:55:26,304 Parse BsubCyc Promoter: 1235\n",
      "2022-07-07 09:55:26,308 writing Promoter.tsv\n",
      "2022-07-07 09:55:26,325 writing Promoter-synonyms.tsv\n",
      "2022-07-07 09:55:26,328 Load BsubCyc: TranscriptionUnit\n",
      "2022-07-07 09:55:26,707 Parse 47/data/transunits.dat\n",
      "2022-07-07 09:55:27,666 Parse BsubCyc TranscriptionUnit: 1647\n",
      "2022-07-07 09:55:27,672 writing TranscriptionUnit.tsv\n",
      "2022-07-07 09:55:27,697 writing TranscriptionUnit-rels.tsv\n",
      "2022-07-07 09:55:27,714 Load BsubCyc: RNA\n",
      "2022-07-07 09:55:27,718 Parse 47/data/rnas.dat\n",
      "2022-07-07 09:55:28,455 Parse BsubCyc RNA: 295\n",
      "2022-07-07 09:55:28,459 writing RNA.tsv\n",
      "2022-07-07 09:55:28,466 writing RNA-rels.tsv\n",
      "2022-07-07 09:55:28,469 Load BsubCyc: Protein\n",
      "2022-07-07 09:55:28,718 Parse 47/data/proteins.dat\n",
      "2022-07-07 09:55:30,710 Parse 47/data/protligandcplxes.dat\n",
      "2022-07-07 09:55:31,544 Parse BsubCyc Protein: 4569\n",
      "2022-07-07 09:55:31,557 writing Protein.tsv\n",
      "2022-07-07 09:55:31,647 writing Protein-synonyms.tsv\n",
      "2022-07-07 09:55:31,720 writing Protein-dblinks.tsv\n",
      "2022-07-07 09:55:31,755 writing Protein-rels.tsv\n",
      "2022-07-07 09:55:31,767 Load BsubCyc: Reaction\n",
      "2022-07-07 09:55:32,114 Parse 47/data/reactions.dat\n",
      "2022-07-07 09:55:33,099 Parse BsubCyc Reaction: 1727\n",
      "2022-07-07 09:55:33,105 writing Reaction.tsv\n",
      "2022-07-07 09:55:33,131 writing Reaction-synonyms.tsv\n",
      "2022-07-07 09:55:33,155 writing Reaction-dblinks.tsv\n",
      "2022-07-07 09:55:33,161 writing Reaction-rels.tsv\n",
      "2022-07-07 09:55:33,177 Load BsubCyc: Pathway\n",
      "2022-07-07 09:55:33,284 Parse 47/data/pathways.dat\n",
      "2022-07-07 09:55:34,046 Parse BsubCyc Pathway: 327\n",
      "2022-07-07 09:55:34,049 writing Pathway.tsv\n",
      "2022-07-07 09:55:34,064 writing Pathway-synonyms.tsv\n",
      "2022-07-07 09:55:34,074 writing Pathway-rels.tsv\n",
      "2022-07-07 09:55:34,079 Load BsubCyc: EnzReaction\n",
      "2022-07-07 09:55:34,396 Parse 47/data/enzrxns.dat\n",
      "2022-07-07 09:55:35,330 Parse BsubCyc EnzReaction: 1356\n",
      "2022-07-07 09:55:35,336 writing EnzReaction.tsv\n",
      "2022-07-07 09:55:35,353 writing EnzReaction-rels.tsv\n",
      "2022-07-07 09:55:35,361 Load BsubCyc: Regulation\n",
      "2022-07-07 09:55:35,504 Parse 47/data/regulation.dat\n",
      "2022-07-07 09:55:36,259 Parse BsubCyc Regulation: 917\n",
      "2022-07-07 09:55:36,263 writing Regulation.tsv\n",
      "2022-07-07 09:55:36,277 writing Regulation-rels.tsv\n",
      "2022-07-07 09:55:36,284 create zip file: BsubCyc-data-47.zip\n"
     ]
    }
   ],
   "source": [
    "# set the biocyc_db to process\n",
    "biocyc_db = DB_BSUBCYC\n",
    "\n",
    "parser = BiocycParser(biocyc_db)\n",
    "parser.parse_and_write_data_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Liquibase changelogs file\n",
    "\n",
    "Liquibase changelog generator expects the input file to be the output zip file from previous step. \n",
    "5 changelog files will be generated.  \n",
    "\n",
    "1. init-changelog:  the scripts will read the parser output zip file, and load data into neo4j database  \n",
    "        \n",
    "2. post load changelogs: this is part of Lifelike biocyc database updates\n",
    "    - link genes to NCBI gene\n",
    "    - set node display name\n",
    "    - set node description, including reaction description as an equation without stoichiometry\n",
    "    - set reaction enzyme_name \n",
    "    - set pathways for gene (for annotation)\n",
    "    - set node property entityType   \n",
    "       \n",
    "3. gds no-collapse changelogs: This is used to generate non-collapse gds database\n",
    "    - all changes listed in #2\n",
    "    - correction reaction input and output directions\n",
    "    - create reversed reactions for reversible reactions if input and output are not the same. Put postfix '_r' in the reversed reaction eid and displayName\n",
    "    - reverse gene to TranscriptionUnit relationship as (TranscriptionUnit)-[:HAS_GENE]->(Gene)\n",
    "    - delete DNA binding site nodes\n",
    "    - delete TYPE_OF relationships\n",
    "    - remove orphan BioCycClass nodes\n",
    "    - remove Enzyme nodes (from Enzyme database)\n",
    "    - set node synonyms property and remove Synonym nodes\n",
    "    - label some compounds as CurrencyMetabolite\n",
    "    - change description property to detail since description is used by sankey for other purpose   \n",
    "    \n",
    "4. gds reg-collapse chanagelogs: This is used to generate reg-collapse gds database.  The database will have parallel edges, therefore need to use multi-graph to run the analysis and traces\n",
    "    - all changes listed in #3\n",
    "    - Collapse reglations\n",
    "        - for reglation with mode '+', change the relationship to 'ACTIVATES' then remove regulation node\n",
    "        - for reglation with mode '-', change the relationship to 'INHIBITS' then remove regulation node\n",
    "        for reglation with mode '', change the relationship to 'REGULATES' then remove regulation node\n",
    "        \n",
    "5. gds changelogs:  This is used to create the general gds database. It has Regulation and EnzReaction nodes collapsed and removed. Multi-graph is needed to run the analysis and traces.\n",
    "    - all changes listed in #4\n",
    "    - collapse EnzReaction\n",
    "        - for EnzReaction regulations, move the regulator to regulate the reactions directly\n",
    "        - for EnzReaction catalyzes, move the protein to catalyze reactions directly\n",
    "        - delete all EnzReaction nodes\n",
    "\n",
    "### Note:\n",
    "The following scripts will generate the general changelogs for different gds databases and lifelike update changelogs.  The lifelike update will need the changelog-xxx-init-xxx.xml and changelog-xxx-post-load-xxx.xml files.  However, since different organism gene naming(accessions) could be different, and they are not always matched with NCBI gene locus tags, you may need different cypher queries to do the gene-gene mapping.  The bsubcyc_liquibase.py is an example about how to override the general cypher queries for the gene mapping.  You could also just manually run the cypher queries after loading biocyc data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the zip file name from previous step output message\n",
    "zip_datafile = 'EcoCyc-data-25.5.zip'\n",
    "biocyc_dbname = DB_ECOCYC\n",
    "author = 'rcai'  # change to your name\n",
    "biocyc_liquibase.generate_changelog_files(zip_datafile, biocyc_dbname, author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run liquibase update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Install liquibase\n",
    "Follow steps in __kg-prototypes/graph-db/migration/liquibase-src/README.md__ to install liquibase, jar files, including the custom java classes.\n",
    "\n",
    "#### 2. Set up database folder for changelogs\n",
    "- copy changelog-mater.xml\n",
    "- copy liquibase.properties, and change the database settings (url, password)\n",
    "- add changelog files into the folder changelogs, and order the changelog files as changelog-xxxx. Liquibase updates will be based on the changelog file name sequence\n",
    "- copy the processed zip file (e.g. PsyringaeCyc-data-24.0.zip) from processed biocyc folder into the folder \"parameter.localSaveFileDir\"\n",
    "\n",
    "### 3. Run liquibase update\n",
    "- create an database in neo4j with name matching the liquibase.properties\n",
    "- run command: \n",
    "```\n",
    "liquibase --log-level=info update\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add new Biocyc GDS databases (different organism)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download the data file from biocyc, and put into {data_dir}/download/biocyc folder\n",
    "2. Add a new db variable in common/constants.py\n",
    "3. In config/congig.yml file, add the dbname-filename mapping \n",
    "4. Run BiocycParser.parse_and_write_data_files\n",
    "5. Run biocyc_liquibase.generate_changelog_files\n",
    "6. create database in neo4j, and run liquibase update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
