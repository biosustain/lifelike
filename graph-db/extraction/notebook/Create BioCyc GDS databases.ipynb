{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create BioCyc GDS databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "github project:  kg-prototypes  \n",
    "branch: graphdb_load\n",
    "\n",
    "#### Steps\n",
    "1. Download individual organism data files.  \n",
    "http://bioinformatics.ai.sri.com/ecocyc/dist/flatfiles-52983746/\n",
    "\n",
    "Curently downloaded files are listed in src/config/config.yml file\n",
    "  - EcoCyc: ecoli_25.5.tar.gz\n",
    "  - HumanCyc: human.tar_25.5.gz\n",
    "  - YeastCyc: yeastcyc_25.5.tar.gz\n",
    "  - PseudomonasCyc: pput160488cyc_25.5.tar.gz\n",
    "  - BsubCyc: bsub_47.tar.gz  \n",
    "  \n",
    "\n",
    "2. Parse the .dat files and process and write formatted data into .tsv files and put into one zip file for liquibase to load into Neo4j graph database  \n",
    "\n",
    "3. Put all post-load scripps into src/config/cypher/biocyc-cypher.yml file, except organism specific cypher queries\n",
    "4. Generate liquibase changelog files\n",
    "5. Move changelog files to migration/liquibase/{dbname}/changelogs folder, and rename.\n",
    "5. Run liquibase update\n",
    "\n",
    "#### Pre-requisition:\n",
    "Since GDS need enzyme name information.  Enzyme database will be loaded into neo4j before loading biocyc data.  The enzyme data will be removed one the enzyme name information is copied to reaction property (displayName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "root = os.getcwd().split('notebook')[0]\n",
    "sys.path.append(os.path.join(root, 'src'))\n",
    "\n",
    "from biocyc.biocyc_parser import *\n",
    "from biocyc import biocyc_liquibase\n",
    "from biocyc import bsubcyc_liquibase \n",
    "from common.constants import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse biocyc data files and generated processed tsv files\n",
    "#### data source\n",
    "Download the data file from biocyc or https://portal.azure.com/#view/Microsoft_Azure_FileStorage/FileShareMenuBlade/~/overview/storageAccountId/%2Fsubscriptions%2F747d6a13-5882-4572-8560-af80d7df69b5%2FresourceGroups%2Flifelike-ecosystem%2Fproviders%2FMicrosoft.Storage%2FstorageAccounts%2Flifelike/path/knowledge-graph/protocol/SMB\n",
    "\n",
    "data files need to put into the input dir: {kg-prototypes}/graph-db/extraction/data/download/biocyc   \n",
    "\n",
    "#### output dir\n",
    "Parser outputs are written in {kg-prototypes}/graph-db/extraction/data/processed/biocyc.     \n",
    "A zip file be generated in the format {biocyc_dbname}-data-{version}.zip under {output dir}/{biocyc_dbname}, where biocyc_dbname is EcoCyc, HumanCyc etc.\n",
    "\n",
    "The biocyc_dbname/data-source-file mapping is in {kg-prototypes}/graph-db/extraction/src/config/config.yml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the biocyc_db to process\n",
    "biocyc_db = DB_ECOCYC\n",
    "\n",
    "parser = BiocycParser(biocyc_db)\n",
    "parser.parse_and_write_data_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Liquibase changelogs file\n",
    "\n",
    "Liquibase changelog generator expects the input file to be the output zip file from previous step. \n",
    "5 changelog files will be generated.  \n",
    "\n",
    "1. init-changelog:  the scripts will read the parser output zip file, and load data into neo4j database  \n",
    "        \n",
    "2. post load changelogs: this is part of Lifelike biocyc database updates\n",
    "    - link genes to NCBI gene\n",
    "    - set node display name\n",
    "    - set node description, including reaction description as an equation without stoichiometry\n",
    "    - set reaction enzyme_name \n",
    "    - set pathways for gene (for annotation)\n",
    "    - set node property entityType   \n",
    "       \n",
    "3. gds no-collapse changelogs: This is used to generate non-collapse gds database\n",
    "    - all changes listed in #2\n",
    "    - correction reaction input and output directions\n",
    "    - create reversed reactions for reversible reactions if input and output are not the same. Put postfix '_r' in the reversed reaction eid and displayName\n",
    "    - reverse gene to TranscriptionUnit relationship as (TranscriptionUnit)-[:HAS_GENE]->(Gene)\n",
    "    - delete DNA binding site nodes\n",
    "    - delete TYPE_OF relationships\n",
    "    - remove orphan BioCycClass nodes\n",
    "    - remove Enzyme nodes (from Enzyme database)\n",
    "    - set node synonyms property and remove Synonym nodes\n",
    "    - label some compounds as CurrencyMetabolite\n",
    "    - change description property to detail since description is used by sankey for other purpose   \n",
    "    \n",
    "4. gds reg-collapse chanagelogs: This is used to generate reg-collapse gds database.  The database will have parallel edges, therefore need to use multi-graph to run the analysis and traces\n",
    "    - all changes listed in #3\n",
    "    - Collapse reglations\n",
    "        - for reglation with mode '+', change the relationship to 'ACTIVATES' then remove regulation node\n",
    "        - for reglation with mode '-', change the relationship to 'INHIBITS' then remove regulation node\n",
    "        for reglation with mode '', change the relationship to 'REGULATES' then remove regulation node\n",
    "        \n",
    "5. gds changelogs:  This is used to create the general gds database. It has Regulation and EnzReaction nodes collapsed and removed. Multi-graph is needed to run the analysis and traces.\n",
    "    - all changes listed in #4\n",
    "    - collapse EnzReaction\n",
    "        - for EnzReaction regulations, move the regulator to regulate the reactions directly\n",
    "        - for EnzReaction catalyzes, move the protein to catalyze reactions directly\n",
    "        - delete all EnzReaction nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_datafile = 'EcoCyc-data-25.5.zip'\n",
    "biocyc_dbname = DB_ECOCYC\n",
    "biocyc_liquibase.generate_changelog_files(zip_datafile, biocyc_dbname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_datafile = 'BsubCyc-data-47.zip'\n",
    "biocyc_dbname = DB_BSUBCYC\n",
    "bsubcyc_liquibase.generate_changelog_files(zip_datafile, biocyc_dbname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run liquibase update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Install liquibase\n",
    "Follow steps in {kg-prototype}/graph-db/migration/liquibase-src/README.md to install liquibase, jar files, including the custom java classes.\n",
    "\n",
    "#### 2. Set up database folder for changelogs\n",
    "- copy changelog-mater.xml\n",
    "- copy liquibase.properties, and change the database settings (url, password)\n",
    "- add changelog files into the folder changelogs, and order the changelog files as changelog-xxxx. Liquibase updates will be based on the changelog file name sequence\n",
    "\n",
    "### 3. Run liquibase update\n",
    "- create an database in neo4j with name matching the liquibase.properties\n",
    "- run command: \n",
    "```\n",
    "liquibase --log-level=info update\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add new Biocyc GDS databases (different organism)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download the data file from biocyc, and put into {data_dir}/download/biocyc folder\n",
    "2. Add a new db variable in common/constants.py\n",
    "3. In config/congig.yml file, add the dbname-filename mapping \n",
    "4. Run BiocycParser.parse_and_write_data_files\n",
    "5. Run biocyc_liquibase.generate_changelog_files\n",
    "6. create database in neo4j, and run liquibase update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
