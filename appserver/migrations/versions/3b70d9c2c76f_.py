""" Adds a directory structure to store projects and maps. Adds
access controls on the project level.

Revision ID: 3b70d9c2c76f
Revises: 868c69bf2137
Create Date: 2020-06-08 15:07:41.373581

"""
from alembic import context
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql
from sqlalchemy.orm.session import Session
from sqlalchemy_utils.types import TSVectorType

from neo4japp.models import (
    AppRole,
    AppUser,
    AccessControlPolicy,
    AccessActionType,
    AccessRuleType,
    Directory,
    Files,
    Project,
    Projects,
    projects_collaborator_role,
)

# revision identifiers, used by Alembic.
revision = '3b70d9c2c76f'
down_revision = '868c69bf2137'
branch_labels = None
depends_on = None

t_files_content = sa.Table(
    'files_content',
    sa.MetaData(),
    sa.Column('id', sa.Integer(), primary_key=True, autoincrement=True),
    sa.Column('raw_file', sa.LargeBinary, nullable=True),
    sa.Column('checksum_sha256', sa.Binary(32), nullable=False, index=True, unique=True),
    sa.Column('creation_date', sa.DateTime, nullable=False, default=sa.func.now()),
)

t_files = sa.Table(
    'files',
    sa.MetaData(),
    sa.Column('id', sa.Integer(), primary_key=True, autoincrement=True),
    sa.Column('filename', sa.String(60)),
    sa.Column('content_id', sa.Integer, sa.ForeignKey(t_files_content.c.id, ondelete='CASCADE')),
    sa.Column('raw_file', sa.LargeBinary, nullable=True),
    sa.Column(
        'dir_id',
        sa.Integer,
        sa.ForeignKey('directory.id'),
        nullable=False,
    ),
    sa.Column(
        'user_id',
        sa.Integer,
        sa.ForeignKey('appuser.id'),
        nullable=False,
    )
)

t_directory = sa.Table(
    'directory',
    sa.MetaData(),
    sa.Column('id', sa.Integer(), primary_key=True, autoincrement=True),
    sa.Column('name', sa.String(200), nullable=False),
    sa.Column(
        'directory_parent_id',
        sa.Integer,
        sa.ForeignKey('directory.id'),
        nullable=True,
    ),
    sa.Column(
        'projects_id',
        sa.Integer,
        sa.ForeignKey('projects.id'),
        nullable=False,
    )
)

t_app_user = sa.Table(
    'appuser',
    sa.MetaData(),
    sa.Column('id', sa.Integer(), primary_key=True),
    sa.Column('username', sa.String(64), index=True, unique=True),
    sa.Column('email', sa.String(120), index=True, unique=True),
    sa.Column('first_name', sa.String(120), nullable=False),
    sa.Column('last_name', sa.String(120), nullable=False),
)

t_app_role = sa.Table(
    'app_role',
    sa.MetaData(),
    sa.Column('id', sa.Integer(), primary_key=True),
    sa.Column('name', sa.String(128), nullable=False, unique=True),
)

t_project = sa.Table(
    'project',
    sa.MetaData(),
    sa.Column('id', sa.Integer(), primary_key=True),
    sa.Column('label', sa.String(250), nullable=False),
    sa.Column('description', sa.Text),
    sa.Column('date_modified', sa.DateTime),
    sa.Column('graph', sa.JSON),
  	sa.Column('author', sa.String(240), nullable=False),
  	sa.Column('public', sa.Boolean(), default=False),
    sa.Column('user_id', sa.Integer, sa.ForeignKey(t_app_user.c.id)),
    sa.Column('dir_id', sa.Integer, sa.ForeignKey(t_directory.c.id)),
    sa.Column('hash_id', sa.String(50), unique=True),
  	sa.Column('search_vector', TSVectorType('label'))
)

t_access_control_policy = sa.Table(
    'access_control_policy',
    sa.MetaData(),
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('action', sa.String(length=50), nullable=False),
    sa.Column('asset_type', sa.String(length=200), nullable=False),
    sa.Column('asset_id', sa.Integer(), nullable=True),
    sa.Column('principal_type', sa.String(length=50), nullable=False),
    sa.Column('principal_id', sa.Integer(), nullable=True),
    sa.Column('rule_type', sa.Enum('ALLOW', 'DENY', name='accessruletype'), nullable=False),
    sa.PrimaryKeyConstraint('id')
)

t_projects = sa.Table(
    'projects',
    sa.MetaData(),
    sa.Column('id', sa.Integer(), primary_key=True, autoincrement=True),
    sa.Column('project_name', sa.String(250), unique=True, nullable=False),
    sa.Column('description', sa.Text),
    sa.Column('creation_date', sa.DateTime, nullable=False, default=sa.func.now()),
    sa.Column('users', sa.ARRAY(sa.Integer), nullable=False)
)


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('directory',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('name', sa.String(length=200), nullable=False),
    sa.Column('directory_parent_id', sa.BigInteger(), nullable=True),
    sa.Column('projects_id', sa.Integer(), nullable=False),
    sa.ForeignKeyConstraint(['directory_parent_id'], ['directory.id'], name=op.f('fk_directory_directory_parent_id_directory')),
    sa.ForeignKeyConstraint(['projects_id'], ['projects.id'], name=op.f('fk_directory_projects_id_projects')),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_directory'))
    )
    op.create_table('projects_collaborator_role',
    sa.Column('appuser_id', sa.Integer(), nullable=False),
    sa.Column('app_role_id', sa.Integer(), nullable=False),
    sa.Column('projects_id', sa.Integer(), nullable=False),
    sa.ForeignKeyConstraint(['app_role_id'], ['app_role.id'], name=op.f('fk_projects_collaborator_role_app_role_id_app_role'), ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['appuser_id'], ['appuser.id'], name=op.f('fk_projects_collaborator_role_appuser_id_appuser'), ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['projects_id'], ['projects.id'], name=op.f('fk_projects_collaborator_role_projects_id_projects'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('appuser_id', 'app_role_id', 'projects_id', name=op.f('pk_projects_collaborator_role'))
    )
    op.add_column('files', sa.Column('dir_id', sa.Integer(), nullable=True))
    op.create_foreign_key(op.f('fk_files_dir_id_directory'), 'files', 'directory', ['dir_id'], ['id'])
    op.add_column('project', sa.Column('dir_id', sa.Integer(), nullable=True))
    op.create_foreign_key(op.f('fk_project_dir_id_directory'), 'project', 'directory', ['dir_id'], ['id'])

    op.alter_column('files', 'dir_id', nullable=False)
    op.alter_column('project', 'dir_id', nullable=False)
    # ### end Alembic commands ###

    if context.get_x_argument(as_dictionary=True).get('data_migrate', None):
        data_upgrades()


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_constraint(op.f('fk_project_dir_id_directory'), 'project', type_='foreignkey')
    op.drop_column('project', 'dir_id')
    op.drop_constraint(op.f('fk_files_dir_id_directory'), 'files', type_='foreignkey')
    op.drop_column('files', 'dir_id')
    op.alter_column('access_control_policy', 'action',
               existing_type=sa.Enum('READ', 'WRITE', name='accessactiontype'),
               type_=sa.VARCHAR(length=50),
               existing_nullable=False)
    op.drop_table('projects_collaborator_role')
    op.drop_table('directory')
    # ### end Alembic commands ###
    # NOTE: In practice perfect downgrades are difficult and in some cases
    # impossible! It is more practical to use database backups/snapshots to
    # "downgrade" the database. Changes to the database that we intend to
    # push to production should always be added to a NEW migration.
    # (i.e. "downgrade forward"!)


def data_upgrades():
    """Add optional data upgrade migrations here"""
    session = Session(op.get_bind())

    conn = op.get_bind()

    actions = postgresql.ENUM('READ', 'WRITE', name='accessactiontype')
    actions.create(op.get_bind())

    op.alter_column('access_control_policy', 'action',
               existing_type=sa.VARCHAR(length=50),
               type_=sa.Enum('READ', 'WRITE', name='accessactiontype'),
               existing_nullable=False,
               postgresql_using="action::accessactiontype")

    # There's only one hardcoded project right now
    row = conn.execute(sa.select([
        t_projects.c.id
    ]).where(t_projects.c.project_name == 'beta-project')).fetchone()

    # This will only be true in development
    if row is None:
        projects_id = conn.execute(
            t_projects.insert().values(
                project_name='beta-project',
                description='',
                users=[],
            )
        ).inserted_primary_key[0]

    else:
        (projects_id,) = row

        # Setup roles for the existing project
        read_role_id = conn.execute(
            t_app_role.insert().values(name='project-read')
        ).inserted_primary_key[0]
        write_role_id = conn.execute(
            t_app_role.insert().values(name='project-write')
        ).inserted_primary_key[0]
        admin_role_id = conn.execute(
            t_app_role.insert().values(name='project-admin')
        ).inserted_primary_key[0]

        # Sets up the 'READ' role
        conn.execute(t_access_control_policy.insert().values(
            action=AccessActionType.READ,
            asset_type=Projects.__tablename__,
            asset_id=projects_id,
            principal_type=AppRole.__tablename__,
            principal_id=read_role_id,
            rule_type=AccessRuleType.ALLOW,
        ))
        conn.execute(t_access_control_policy.insert().values(
            action=AccessActionType.WRITE,
            asset_type=Projects.__tablename__,
            asset_id=projects_id,
            principal_type=AppRole.__tablename__,
            principal_id=read_role_id,
            rule_type=AccessRuleType.DENY,
        ))

        # Sets up the 'WRITE' role
        conn.execute(t_access_control_policy.insert().values(
            action=AccessActionType.READ,
            asset_type=Projects.__tablename__,
            asset_id=projects_id,
            principal_type=AppRole.__tablename__,
            principal_id=write_role_id,
            rule_type=AccessRuleType.ALLOW,
        ))
        conn.execute(t_access_control_policy.insert().values(
            action=AccessActionType.WRITE,
            asset_type=Projects.__tablename__,
            asset_id=projects_id,
            principal_type=AppRole.__tablename__,
            principal_id=write_role_id,
            rule_type=AccessRuleType.ALLOW,
        ))

        # Sets up the 'ADMIN' role
        conn.execute(t_access_control_policy.insert().values(
            action=AccessActionType.READ,
            asset_type=Projects.__tablename__,
            asset_id=projects_id,
            principal_type=AppRole.__tablename__,
            principal_id=admin_role_id,
            rule_type=AccessRuleType.ALLOW,
        ))
        conn.execute(t_access_control_policy.insert().values(
            action=AccessActionType.WRITE,
            asset_type=Projects.__tablename__,
            asset_id=projects_id,
            principal_type=AppRole.__tablename__,
            principal_id=admin_role_id,
            rule_type=AccessRuleType.ALLOW,
        ))

    # Bucket everything into a single directory
    directory_id = conn.execute(
        t_directory.insert().values(
            name='/',
            directory_parent_id=None,
            projects_id=projects_id,
        )
    ).inserted_primary_key[0]

    # Get writer role
    write_role_id = conn.execute(sa.select([
        t_app_role.c.id
    ]).where(t_app_role.c.name == 'project-write')).fetchone()

    # If none, create it
    if write_role_id is None:
        write_role_id = conn.execute(
            t_app_role.insert().values(name='project-write')
        ).inserted_primary_key[0]

    # Set all existing users to write role
    user_ids = conn.execute(sa.select([
        t_app_user.c.id
    ])).fetchall()
    
    for user_id in user_ids:
        session.execute(
            projects_collaborator_role.insert(),
            [dict(
                appuser_id=user_id,
                projects_id=projects_id,
                app_role_id=write_role_id,
            )]
        )
        session.flush()

    file_ids = conn.execute(sa.select([
        t_files.c.id
    ])).fetchall()
    for file_id in file_ids:
        conn.execute(t_files
                     .update()
                     .where(t_files.c.id == file_id)
                     .values(dir_id=directory_id))

    proj_ids = conn.execute(sa.select([
        t_project.c.id
    ])).fetchall()
    for proj_id in proj_ids:
        conn.execute(t_project
                     .update()
                     .where(t_project.c.id == proj_id)
                     .values(dir_id=directory_id))

    session.commit()


def data_downgrades():
    """Add optional data downgrade migrations here"""
    pass
