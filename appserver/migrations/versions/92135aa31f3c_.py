"""Fix term Biocyc to be BioCyc in enrichment json and attempt to fix any other issues with the json

Revision ID: 92135aa31f3c
Revises: d509d9c60fdb
Create Date: 2021-07-27 17:35:58.662599

"""
import hashlib
import json
from alembic import context
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

from sqlalchemy.sql import table, column, and_
from sqlalchemy.orm.session import Session

from marshmallow import fields

from neo4japp.schemas.base import CamelCaseSchema

from migrations.utils import window_chunk
from neo4japp.constants import FILE_MIME_TYPE_ENRICHMENT_TABLE
from neo4japp.models import Files, FileContent
from neo4japp.schemas.formats.enrichment_tables import validate_enrichment_table, current_version

# revision identifiers, used by Alembic.
revision = '92135aa31f3c'
down_revision = 'd509d9c60fdb'
branch_labels = None
depends_on = None


# copied from neo4japp.schemas.enrichment
# changed to snakecase to easily convert to camelcase
class EnrichmentValue(CamelCaseSchema):
    text = fields.String(required=True)
    annotated_text = fields.String(allow_none=True)
    link = fields.String(required=True)


class EnrichedGene(CamelCaseSchema):
    imported = fields.String(allow_none=True)
    matched = fields.String(allow_none=True)
    full_name = fields.String(allow_none=True)
    annotated_imported = fields.String(allow_none=True)
    annotated_matched = fields.String(allow_none=True)
    annotated_full_name = fields.String(allow_none=True)
    link = fields.String(allow_none=True)
    domains = fields.Dict(
        keys=fields.String(), values=fields.Dict(
            keys=fields.String(), values=fields.Nested(EnrichmentValue)), allow_none=True)


class DomainInfo(CamelCaseSchema):
    labels = fields.List(fields.String())


class EnrichmentResult(CamelCaseSchema):
    version = fields.String(required=True)
    domain_info = fields.Dict(
        keys=fields.String(), values=fields.Nested(DomainInfo), required=True)
    genes = fields.List(fields.Nested(EnrichedGene), required=True)


class EnrichmentData(CamelCaseSchema):
    genes = fields.String(required=True)
    tax_id = fields.String(required=True)
    organism = fields.String(required=True)
    sources = fields.List(fields.String())


class EnrichmentTableSchema(CamelCaseSchema):
    data = fields.Nested(EnrichmentData, required=True)
    result = fields.Nested(EnrichmentResult, required=True)


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    # ### end Alembic commands ###
    if context.get_x_argument(as_dictionary=True).get('data_migrate', None):
        data_upgrades()


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###
    # NOTE: In practice perfect downgrades are difficult and in some cases
    # impossible! It is more practical to use database backups/snapshots to
    # "downgrade" the database. Changes to the database that we intend to
    # push to production should always be added to a NEW migration.
    # (i.e. "downgrade forward"!)


def data_upgrades():
    """Add optional data upgrade migrations here"""
    conn = op.get_bind()
    session = Session(conn)

    tableclause1 = table(
        'files',
        column('id', sa.Integer),
        column('content_id', sa.Integer),
        column('mime_type', sa.String),
        column('enrichment_annotations', postgresql.JSONB))

    tableclause2 = table(
        'files_content',
        column('id', sa.Integer),
        column('raw_file', sa.LargeBinary))

    files = conn.execution_options(stream_results=True).execute(sa.select([
        tableclause1.c.id.label('file_id'),
        tableclause1.c.enrichment_annotations,
        tableclause2.c.id.label('file_content_id'),
        tableclause2.c.raw_file
    ]).where(
        and_(
            tableclause1.c.mime_type == FILE_MIME_TYPE_ENRICHMENT_TABLE,
            tableclause1.c.enrichment_annotations.isnot(None),
            tableclause1.c.content_id == tableclause2.c.id
        )
    ))

    file_content_hashes = {}
    for chunk in window_chunk(files, 25):
        raws_to_update = []
        files_to_update = []
        for fid, annos, fcid, raw in chunk:
            current = raw
            found_err = False

            try:
                json.loads(current)
            except Exception:
                # TODO: what to do with these?
                # they're literal strings, e.g 'AK3,AK4/9606/Homo sapiens/...'
                # only in STAGE db
                continue
            else:
                while True:
                    try:
                        enriched_table = json.loads(current)
                        validate_enrichment_table(enriched_table)

                        if found_err:
                            file_obj = {'id': fid}
                            new_hash = hashlib.sha256(current).digest()

                            # because we are fixing JSONs, it is possible
                            # to have collision since fixing a JSON
                            # can potentially result in an existing JSON
                            if new_hash not in file_content_hashes:
                                file_content_hashes[new_hash] = fcid
                                raws_to_update.append({'id': fcid, 'raw_file': current, 'checksum_sha256': new_hash})  # noqa
                            else:
                                file_obj['content_id'] = file_content_hashes[new_hash]

                            if annos:
                                if 'result' not in annos and 'version' in annos:
                                    annos = {'result': annos}
                                annos['result']['version'] = current_version
                                annos['data'] = enriched_table['data']

                                if 'domainInfo' not in annos['result']:
                                    # in EnrichmentAnnotationsView, the enrichment annotations
                                    # is being returned to the client using EnrichmentTableSchema
                                    # since what is in the db validates against that schema
                                    # it should be the same here
                                    annos = EnrichmentTableSchema().dump(annos)
                                validate_enrichment_table(annos)
                                file_obj['enrichment_annotations'] = annos

                            if len(file_obj) > 1:
                                files_to_update.append(file_obj)
                        break
                    except Exception as e:
                        found_err = True
                        err = str(e)

                        if 'data.result.version' in err:
                            enriched_table['result']['version'] = current_version

                        if err == 'data.data must be object':
                            data_split = enriched_table['data'].split('/')
                            enriched_table['data'] = {
                                'genes': data_split[0],
                                'taxId': data_split[1],
                                'organism': data_split[2],
                                'sources': [d for d in data_split[-1].split(',')] if data_split[-1] else []  # noqa
                            }

                        if 'data.data.sources' in err and 'must be one of' in err:
                            curr_sources = enriched_table['data']['sources']
                            new_sources = []
                            for s in curr_sources:
                                if s.lower() == 'biocyc':
                                    new_sources.append('BioCyc')
                                elif s.lower() == 'go':
                                    new_sources.append('GO')
                                elif s.lower() == 'kegg':
                                    new_sources.append('KEGG')
                                elif s.lower() == 'regulon':
                                    new_sources.append('Regulon')
                                elif s.lower() == 'string':
                                    new_sources.append('String')
                                elif s.lower() == 'uniprot':
                                    new_sources.append('UniProt')
                            enriched_table['data']['sources'] = new_sources

                        current = json.dumps(enriched_table, separators=(',', ':')).encode('utf-8')
        try:
            session.bulk_update_mappings(Files, files_to_update)
            session.bulk_update_mappings(FileContent, raws_to_update)
            session.commit()
        except Exception:
            raise


def data_downgrades():
    """Add optional data downgrade migrations here"""
    pass
